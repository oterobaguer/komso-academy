{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "01-pytorch-intro.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bvGuyj6SKMj"
      },
      "source": [
        "# Introduction to PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3dnQsFsSKMj"
      },
      "source": [
        "Python-based scientific computing package for two main purposes:\n",
        "\n",
        "* Replacement for **NumPy** to use the power of GPUs\n",
        "* **Deep learning** research platform that provides maximum flexibility and speed\n",
        "\n",
        "\n",
        "Sources:\n",
        "\n",
        "\n",
        "*   https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\n",
        "*   https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pYCH-TZxaLH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GTwBGjwxUY2"
      },
      "source": [
        "### 0) NumPy reminder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2_ZM0zfxgpb"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMx5frqYSKMk"
      },
      "source": [
        "### 1) Basic operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkKj-EOBSKMl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvNFlvMrSKMo"
      },
      "source": [
        "### 2) Bridge to NumPy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84OXjbq_SKMo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y-9sMUBSKMr"
      },
      "source": [
        "### 3) Automatic Differentiation\n",
        "\n",
        "Mathematically, if you have a vector valued function $y=f(x)$, then the gradient of $y$  with respect to $x$  is a Jacobian matrix:\n",
        "\n",
        "\\begin{split}J=\\left(\\begin{array}{ccc}\n",
        " \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
        " \\vdots & \\ddots & \\vdots\\\\\n",
        " \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        " \\end{array}\\right)\\end{split}\n",
        "\n",
        "Generally speaking, `torch.autograd` is an engine for computing vector-Jacobian product. That is, given any vector $v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T}$  compute the product   $v^{T}\\cdot J$.\n",
        "\n",
        "\n",
        "If $v$ happens to be happens to be the gradient of a scalar function $l = g(y)$, that is $v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}$, then by the chain rule, the vector-Jacobian product would be the gradient of $l$ with respect to $x$:\n",
        "\n",
        "\\begin{split}J^{T}\\cdot v=\\left(\\begin{array}{ccc}\n",
        " \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
        " \\vdots & \\ddots & \\vdots\\\\\n",
        " \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        " \\end{array}\\right)\\left(\\begin{array}{c}\n",
        " \\frac{\\partial l}{\\partial y_{1}}\\\\\n",
        " \\vdots\\\\\n",
        " \\frac{\\partial l}{\\partial y_{m}}\n",
        " \\end{array}\\right)=\\left(\\begin{array}{c}\n",
        " \\frac{\\partial l}{\\partial x_{1}}\\\\\n",
        " \\vdots\\\\\n",
        " \\frac{\\partial l}{\\partial x_{n}}\n",
        " \\end{array}\\right)\\end{split}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8QN3CQFSKMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKX1k9JFSKMt"
      },
      "source": [
        "### 4) Linear regression example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTFx62iBSKMu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qJ_bLMS9-TE"
      },
      "source": [
        "### 5) Non-linear regression example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXtaVI0L-DhD"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}